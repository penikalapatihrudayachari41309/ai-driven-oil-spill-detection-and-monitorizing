---

# ğŸŒŠ AI-Driven Oil Spill Detection and Monitoring

![Python](https://img.shields.io/badge/Python-3.9+-blue)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange)
![Streamlit](https://img.shields.io/badge/Streamlit-App-red)
![SAR](https://img.shields.io/badge/SAR-Remote%20Sensing-green)

---

## ğŸ“Œ Project Overview

Oil spills pose severe threats to marine ecosystems, coastal environments, and economies. Traditional monitoring methods rely on manual inspection of satellite imagery, which is time-consuming, labor-intensive, and often delayed.

This project presents an **AI-driven oil spill detection and segmentation system** using **Synthetic Aperture Radar (SAR)** satellite imagery and a **U-Net deep learning architecture**. The system automatically identifies and localizes oil spill regions and is deployed via a **Streamlit web application** for real-time inference and visualization.

ğŸ”— **Live Application**
ğŸ‘‰ [https://ai-driven-oil-spill-detection-and-monitorizing-phaa.streamlit.app/](https://ai-driven-oil-spill-detection-and-monitorizing-phaa.streamlit.app/)

---

## ğŸ§  System Architecture

The system follows a modular, end-to-end pipeline:

1. SAR Image Acquisition
2. SAR-Specific Denoising (Speckle Noise Reduction)
3. Deep Learning-Based Segmentation (U-Net)
4. Mask Generation and Overlay Visualization
5. Web Deployment via Streamlit

This architecture enables automated oil spill monitoring from raw satellite imagery to user-interactive prediction outputs.

---

## ğŸ“‚ Dataset

* **Dataset Name**: Deep SAR (SOS) Oil Spill Dataset
* **Source**: Kaggle
* **Archived Version**: [https://zenodo.org/records/8346860](https://zenodo.org/records/8346860)
* **Data Type**: SAR images with binary segmentation masks
* **Sensors**: Sentinel-1 and PALSAR

### ğŸ“Š Dataset Statistics

#### Initial Dataset (Before Cleanup)

| Split      | Images | Masks |
| ---------- | ------ | ----- |
| Training   | 6455   | 6459  |
| Validation | 1389   | 1615  |

#### Data Cleaning

* âŒ Removed **4** misaligned training masks
* âŒ Removed **226** misaligned validation masks
* âœ… Ensured **1:1 imageâ€“mask correspondence**

#### Final Dataset (After Splitting)

| Split      | Imageâ€“Mask Pairs |
| ---------- | ---------------- |
| Training   | 5164             |
| Validation | 1389             |
| Test       | 1291             |

ğŸ” **Augmented Training Set Size**: 10,328 imageâ€“mask pairs

---

## ğŸ§ª Data Exploration & Preprocessing

### âœ” Exploratory Analysis

* Visualized representative imageâ€“mask pairs
* Studied pixel-level statistical properties of spill and non-spill regions
* Observed **lower radar backscatter intensity in oil spill regions**, a known SAR phenomenon

---

### ğŸ“Š Pixel Intensity Analysis: Spill vs. Non-Spill Regions

| Region Type           | Total Pixels | Mean Intensity | Std. Deviation |
| --------------------- | ------------ | -------------- | -------------- |
| **Spill Regions**     | 57,388       | **90.28**      | 51.32          |
| **Non-Spill Regions** | 270,292      | **140.12**     | 43.19          |

**Key Insight:** Oil slicks dampen capillary waves, reducing SAR backscatter and creating strong segmentation cues.

---

### âœ” Preprocessing Steps

* **Resizing**: `128 Ã— 128`
* **Normalization**: Pixel values scaled to `[0, 1]`
* **SAR-Specific Denoising**:

```python
skimage.restoration.denoise_wavelet(
    wavelet="db1",
    mode="soft",
    sigma=0.05
)
```

---

### âœ” Data Augmentation (Training Only)

Implemented using **Albumentations**:

* Horizontal & Vertical Flips
* Rotation (Â±30Â°)
* Random Brightness & Contrast

---

## ğŸ§© Model Architecture (U-Net)

* **Input Shape**: `(128, 128, 1)`
* **Encoder Filters**: `32 â†’ 64 â†’ 128`
* **Bottleneck**: `256`
* **Decoder Filters**: `128 â†’ 64 â†’ 32`
* **Output**: `1Ã—1 Conv + Sigmoid`

Optimized for **accuracy + efficiency** on SAR data.

---

## âš™ï¸ Training Configuration

* **Framework**: TensorFlow / Keras
* **Optimizer**: Adam (`1e-4`)
* **Loss**: Binary Cross-Entropy
* **Metrics**: Mean IoU, Accuracy, Precision, Recall
* **Batch Size**: 32
* **Epochs**: 50 (Early Stopping)
* **Mixed Precision**: `mixed_float16`

---

## ğŸ“ˆ Model Evaluation (Test Set)

| Metric          | Value  |
| --------------- | ------ |
| Loss            | 0.1992 |
| Mean IoU        | 0.3779 |
| Binary Accuracy | 0.9168 |
| Precision       | 0.8490 |
| Recall          | 0.8035 |

âœ” Strong generalization
âœ” Balanced precisionâ€“recall

---

## ğŸŒ Deployment (Streamlit App)

### Features

* Upload SAR images
* Real-time inference
* Oil spill detection & segmentation
* Mask overlay visualization
* Download predicted masks

---

## âœ… Requirements & Dependencies

### ğŸ”§ Hardware Requirements

* **GPU access recommended**
* Designed for **Google Colab (CUDA-enabled GPU)**

---

### ğŸ Software Requirements

#### Core Python Libraries

* `os`, `shutil`, `random`, `math`, `io (BytesIO)`

#### Numerical Computing

* `numpy`

#### Image Processing

* `Pillow (PIL)`
* `opencv-python (cv2)`
* `scikit-image` (for `denoise_wavelet`)

#### Data Augmentation

* `albumentations==1.3.1`

#### Deep Learning

* `tensorflow` (with `tensorflow.keras`)

#### Visualization

* `matplotlib`
* `IPython.display`

#### Web Application

* `streamlit`
* `pyngrok`

---

### ğŸ“¦ Installation (Colab / Local)

```bash
pip install tensorflow numpy pillow albumentations scikit-image \
streamlit pyngrok opencv-python matplotlib
```

---

### ğŸ“ Dataset Requirements

Dataset must be placed in **Google Drive** at:

```text
/content/drive/MyDrive/Deep SAR (SOS) Dataset/
```

Expected structure:

```text
dataset/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ train/
â”‚   â””â”€â”€ val/
â”œâ”€â”€ masks/
â”‚   â””â”€â”€ masks/
â”‚       â”œâ”€â”€ train/
â”‚       â””â”€â”€ val/
```

---

### ğŸ”‘ Ngrok Authentication

Required for public deployment from Colab:

```bash
ngrok authtoken YOUR_NGROK_AUTH_TOKEN
```

---

## ğŸš€ Run the App (Colab + LocalTunnel)

```bash
pip install streamlit
npm install -g localtunnel
streamlit run app.py --server.port 8501 & npx localtunnel --port 8501
```

---

## ğŸ“ Project Structure

```text
â”œâ”€â”€ app.py
â”œâ”€â”€ models/
â”‚   â””â”€â”€ unet_oil_spill_segmentation_model_128x128.keras
â”œâ”€â”€ dataset_processed_128x128/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ masks/
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ Presentation_and_Documentation.ipynb
â”œâ”€â”€ README.md
```

---

## ğŸ”® Future Enhancements

* Dice / Focal Loss
* CRF-based post-processing
* Multi-sensor fusion
* Real-time alert APIs
* Confidence estimation

---

## ğŸ“œ License

Released under the **MIT License**.

---
Just tell me ğŸ‘Œ
